{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wltDCN1IrWg-"
      },
      "source": [
        "# Visual Questions Answering simplest examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_9XXhnurjU7"
      },
      "source": [
        "First we need to install easy-vqa this is the data set we will be using in our experiments for mor details follow the link:https://github.com/vzhou842/easy-VQA\n",
        "\n",
        "easy-VQA contains\n",
        "4,000 train images and 38,575 train questions.\n",
        "\n",
        "*   1,000 test images and 9,673 test questions.\n",
        "*   13 total possible answers.\n",
        "*   28,407 training questions that are yes/no.\n",
        "*   7,136 testing questions that are yes/no.\n",
        "\n",
        "All images are 64x64 color images\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK_4Mf7rFuDj",
        "outputId": "36ec2948-d53a-4a11-a430-fe80b7c87203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting easy-vqa\n",
            "  Downloading easy_vqa-1.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 4.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: easy-vqa\n",
            "Successfully installed easy-vqa-1.0\n"
          ]
        }
      ],
      "source": [
        "pip install easy-vqa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VvWK17fs2F0"
      },
      "source": [
        "# Making Data set Ready\n",
        "In this section we have written the code to get the data set ready for our analysis.\n",
        "\n",
        "\n",
        "1.   Reading Questions and there actual answers\n",
        "2.   Reading all the images and saving there paths and data into arrays\n",
        "3.   Getting Ready the training and testing data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJIQLAB3FTvs"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from easy_vqa import get_train_questions, get_test_questions, get_train_image_paths, get_test_image_paths, get_answers\n",
        "\n",
        "def setup():\n",
        "  print('\\n--- Reading questions...')\n",
        "\n",
        "  # Use the easy-vqa package\n",
        "  train_qs, train_answers, train_image_ids = get_train_questions()\n",
        "  test_qs, test_answers, test_image_ids = get_test_questions()\n",
        "  # print(\"here1\",test_qs[0])\n",
        "  print(f'Read {len(train_qs)} training questions and {len(test_qs)} testing questions.')\n",
        "\n",
        "\n",
        "  print('\\n--- Reading answers...')\n",
        "  # Read answers from the easy-vqa package\n",
        "  all_answers = get_answers()\n",
        "  num_answers = len(all_answers)\n",
        "  print(f'Found {num_answers} total answers:')\n",
        "  print(all_answers)\n",
        "\n",
        "\n",
        "  print('\\n--- Reading/processing images...')\n",
        "  def load_and_proccess_image(image_path):\n",
        "    # Load image, then scale and shift pixel values to [-0.5, 0.5]\n",
        "    im = img_to_array(load_img(image_path))\n",
        "    return im / 255 - 0.5\n",
        "\n",
        "  def read_images(paths):\n",
        "    # paths is a dict mapping image ID to image path\n",
        "    # Returns a dict mapping image ID to the processed image\n",
        "    ims = {}\n",
        "    for image_id, image_path in paths.items():\n",
        "      ims[image_id] = load_and_proccess_image(image_path)\n",
        "    return ims\n",
        "\n",
        "\n",
        "  # Read images from the easy-vqa package\n",
        "  test_paths = get_test_image_paths()\n",
        "  train_ims = read_images(get_train_image_paths())\n",
        "  test_ims = read_images(get_test_image_paths())\n",
        "  im_shape = train_ims[0].shape\n",
        "  print(f'Read {len(train_ims)} training images and {len(test_ims)} testing images.')\n",
        "  print(f'Each image has shape {im_shape}.')\n",
        "\n",
        "\n",
        "  print('\\n--- Fitting question tokenizer...')\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(train_qs)\n",
        "\n",
        "  # We add one because the Keras Tokenizer reserves index 0 and never uses it.\n",
        "  vocab_size = len(tokenizer.word_index) + 1\n",
        "  print(f'Vocab Size: {vocab_size}')\n",
        "  print(tokenizer.word_index)\n",
        "\n",
        "\n",
        "  print('\\n--- Converting questions to bags of words...')\n",
        "  train_X_seqs = tokenizer.texts_to_matrix(train_qs)\n",
        "  test_X_seqs = tokenizer.texts_to_matrix(test_qs)\n",
        "  print(f'Example question bag of words: {test_X_seqs[0]}')\n",
        "\n",
        "\n",
        "  print('\\n--- Creating model input images...')\n",
        "  train_X_ims = np.array([train_ims[id] for id in train_image_ids])\n",
        "  test_X_ims = np.array([test_ims[id] for id in test_image_ids])\n",
        "\n",
        "\n",
        "  print('\\n--- Creating model outputs...')\n",
        "  train_answer_indices = [all_answers.index(a) for a in train_answers]\n",
        "  test_answer_indices = [all_answers.index(a) for a in test_answers]\n",
        "  train_Y = to_categorical(train_answer_indices)\n",
        "  test_Y = to_categorical(test_answer_indices)\n",
        "  print(f'Example model output: {train_Y[0]}')\n",
        "\n",
        "  return (train_X_ims, train_X_seqs, train_Y, test_X_ims, test_X_seqs,\n",
        "          test_Y, im_shape, vocab_size, num_answers,\n",
        "          all_answers, test_qs, test_answer_indices,test_paths,test_qs)  # for the analyze script\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRzw2k2juPtZ"
      },
      "source": [
        "# Creating Model:\n",
        "Here we create the Model for our Visual Question Answering this is one of the simplest model as the data set we are using is very simple.\n",
        "\n",
        "The first part show the CNN model for Images while in the second part we used a fully connected layers for the questions. In the third part we have combined the two models for the prediction of the questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsdPwXEtFnzt"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Multiply\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_model(im_shape, vocab_size, num_answers):\n",
        "  # The CNN\n",
        "  im_input = Input(shape=im_shape)\n",
        "  x1 = Conv2D(8, 3, padding='same')(im_input)\n",
        "  x1 = MaxPooling2D()(x1)\n",
        "  x1 = Conv2D(16, 3, padding='same')(x1)\n",
        "  x1 = MaxPooling2D()(x1)\n",
        "  x1 = Flatten()(x1)\n",
        "  x1 = Dense(32, activation='tanh')(x1)\n",
        "\n",
        "  # The question network\n",
        "  q_input = Input(shape=(vocab_size,))\n",
        "  x2 = Dense(32, activation='tanh')(q_input)\n",
        "  x2 = Dense(32, activation='tanh')(x2)\n",
        "\n",
        "  # Merge -> output\n",
        "  out = Multiply()([x1, x2])\n",
        "  out = Dense(32, activation='tanh')(out)\n",
        "  out = Dense(num_answers, activation='softmax')(out)\n",
        "\n",
        "  model = Model(inputs=[im_input, q_input], outputs=out)\n",
        "  model.compile(Adam(learning_rate=5e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vacKcITWwlZq"
      },
      "source": [
        "# Training:\n",
        "Now training our model using the data prepared intially"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_-I7vamGHDe",
        "outputId": "9960cf9b-1f41-4813-dafe-cbca8997d28f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Reading questions...\n",
            "Read 38575 training questions and 9673 testing questions.\n",
            "\n",
            "--- Reading answers...\n",
            "Found 13 total answers:\n",
            "['circle', 'green', 'red', 'gray', 'yes', 'teal', 'black', 'rectangle', 'yellow', 'triangle', 'brown', 'blue', 'no']\n",
            "\n",
            "--- Reading/processing images...\n",
            "Read 4000 training images and 1000 testing images.\n",
            "Each image has shape (64, 64, 3).\n",
            "\n",
            "--- Fitting question tokenizer...\n",
            "Vocab Size: 27\n",
            "{'is': 1, 'shape': 2, 'the': 3, 'a': 4, 'image': 5, 'there': 6, 'not': 7, 'what': 8, 'present': 9, 'does': 10, 'contain': 11, 'in': 12, 'color': 13, 'no': 14, 'circle': 15, 'rectangle': 16, 'triangle': 17, 'brown': 18, 'yellow': 19, 'gray': 20, 'teal': 21, 'black': 22, 'red': 23, 'green': 24, 'blue': 25, 'of': 26}\n",
            "\n",
            "--- Converting questions to bags of words...\n",
            "Example question bag of words: [0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0.]\n",
            "\n",
            "--- Creating model input images...\n",
            "\n",
            "--- Creating model outputs...\n",
            "Example model output: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "\n",
            "--- Building model...\n",
            "\n",
            "--- Training model...\n",
            "Epoch 1/8\n",
            "1206/1206 [==============================] - 102s 83ms/step - loss: 0.9098 - accuracy: 0.6432 - val_loss: 0.7573 - val_accuracy: 0.6657\n",
            "Epoch 2/8\n",
            "1206/1206 [==============================] - 95s 79ms/step - loss: 0.7501 - accuracy: 0.6728 - val_loss: 0.7076 - val_accuracy: 0.6879\n",
            "Epoch 3/8\n",
            "1206/1206 [==============================] - 95s 79ms/step - loss: 0.6704 - accuracy: 0.7124 - val_loss: 0.6105 - val_accuracy: 0.7485\n",
            "Epoch 4/8\n",
            "1206/1206 [==============================] - 93s 77ms/step - loss: 0.5794 - accuracy: 0.7534 - val_loss: 0.5415 - val_accuracy: 0.7704\n",
            "Epoch 5/8\n",
            "1206/1206 [==============================] - 93s 77ms/step - loss: 0.5234 - accuracy: 0.7690 - val_loss: 0.5038 - val_accuracy: 0.7712\n",
            "Epoch 6/8\n",
            "1206/1206 [==============================] - 96s 80ms/step - loss: 0.4755 - accuracy: 0.7765 - val_loss: 0.4657 - val_accuracy: 0.7746\n",
            "Epoch 7/8\n",
            "1206/1206 [==============================] - 93s 77ms/step - loss: 0.4274 - accuracy: 0.7883 - val_loss: 0.4270 - val_accuracy: 0.7880\n",
            "Epoch 8/8\n",
            "1206/1206 [==============================] - 92s 76ms/step - loss: 0.3791 - accuracy: 0.8176 - val_loss: 0.3952 - val_accuracy: 0.8133\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f911766b040>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import argparse\n",
        "\n",
        "# Prepare data\n",
        "train_X_ims, train_X_seqs, train_Y, test_X_ims, test_X_seqs, test_Y, im_shape, vocab_size, num_answers, _, _, _, _,_ = setup()\n",
        "\n",
        "print('\\n--- Building model...')\n",
        "model = build_model(im_shape, vocab_size, num_answers)\n",
        "checkpoint = ModelCheckpoint('model.h5', save_best_only=True)\n",
        "\n",
        "print('\\n--- Training model...')\n",
        "model.fit(\n",
        "  [train_X_ims, train_X_seqs],\n",
        "  train_Y,\n",
        "  validation_data=([test_X_ims, test_X_seqs], test_Y),\n",
        "  shuffle=True,\n",
        "  epochs=8,\n",
        "  callbacks=[checkpoint],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjT14k6GxK_y"
      },
      "source": [
        "# Analysis of our Experiments:\n",
        "The following code is for performing analysis against our model\n",
        "where the first part represent the accuracy stats against each type of the answers. The scond part represents Errors. In last part represents the questions which were answerd wrongly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KG0hP1buIegP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f22b91fe-3e7d-4632-bd43-bc1acf9c7f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Reading questions...\n",
            "Read 38575 training questions and 9673 testing questions.\n",
            "\n",
            "--- Reading answers...\n",
            "Found 13 total answers:\n",
            "['circle', 'green', 'red', 'gray', 'yes', 'teal', 'black', 'rectangle', 'yellow', 'triangle', 'brown', 'blue', 'no']\n",
            "\n",
            "--- Reading/processing images...\n",
            "Read 4000 training images and 1000 testing images.\n",
            "Each image has shape (64, 64, 3).\n",
            "\n",
            "--- Fitting question tokenizer...\n",
            "Vocab Size: 27\n",
            "{'is': 1, 'shape': 2, 'the': 3, 'a': 4, 'image': 5, 'there': 6, 'not': 7, 'what': 8, 'present': 9, 'does': 10, 'contain': 11, 'in': 12, 'color': 13, 'no': 14, 'circle': 15, 'rectangle': 16, 'triangle': 17, 'brown': 18, 'yellow': 19, 'gray': 20, 'teal': 21, 'black': 22, 'red': 23, 'green': 24, 'blue': 25, 'of': 26}\n",
            "\n",
            "--- Converting questions to bags of words...\n",
            "Example question bag of words: [0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0.]\n",
            "\n",
            "--- Creating model input images...\n",
            "\n",
            "--- Creating model outputs...\n",
            "Example model output: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "\n",
            "--- Building model...\n",
            "303/303 [==============================] - 9s 29ms/step\n",
            "\n",
            "Statistics for answer 0, circle\n",
            "Min: 5.304691512719728e-06, Max: 0.582779049873352, Mean: 0.048731159418821335\n",
            "\n",
            "Statistics for answer 1, green\n",
            "Min: 6.33598460808571e-07, Max: 0.9946538805961609, Mean: 0.016644906252622604\n",
            "\n",
            "Statistics for answer 2, red\n",
            "Min: 2.143310211977223e-06, Max: 0.982636034488678, Mean: 0.014372113160789013\n",
            "\n",
            "Statistics for answer 3, gray\n",
            "Min: 8.922855698756393e-08, Max: 0.937637448310852, Mean: 0.021477248519659042\n",
            "\n",
            "Statistics for answer 4, yes\n",
            "Min: 8.328696310400119e-08, Max: 0.9981213212013245, Mean: 0.3614104986190796\n",
            "\n",
            "Statistics for answer 5, teal\n",
            "Min: 6.714911933158874e-07, Max: 0.9932044744491577, Mean: 0.014774886891245842\n",
            "\n",
            "Statistics for answer 6, black\n",
            "Min: 6.310834805844934e-07, Max: 0.9799439907073975, Mean: 0.01514107920229435\n",
            "\n",
            "Statistics for answer 7, rectangle\n",
            "Min: 4.576269930112176e-06, Max: 0.788507878780365, Mean: 0.04313543066382408\n",
            "\n",
            "Statistics for answer 8, yellow\n",
            "Min: 8.580934149904351e-07, Max: 0.9971634745597839, Mean: 0.016963530331850052\n",
            "\n",
            "Statistics for answer 9, triangle\n",
            "Min: 1.7179299902636558e-06, Max: 0.8337938785552979, Mean: 0.03798181936144829\n",
            "\n",
            "Statistics for answer 10, brown\n",
            "Min: 4.383078703540377e-06, Max: 0.9359989762306213, Mean: 0.01839848980307579\n",
            "\n",
            "Statistics for answer 11, blue\n",
            "Min: 6.333083746312695e-08, Max: 0.9992507696151733, Mean: 0.015873059630393982\n",
            "\n",
            "Statistics for answer 12, no\n",
            "Min: 1.260378553524788e-06, Max: 0.9988571405410767, Mean: 0.3750957250595093\n",
            "\n",
            "\n",
            "total error: 0.1867052620696785\n",
            "Indexes are, in order, shapes, yes/no, colors\n",
            "Rows are class of answer, columns are class of prediction\n",
            "0.4186046511627907\t0.0\t0.0\n",
            "\n",
            "0.0\t0.5171650055370985\t0.0\n",
            "\n",
            "0.0\t0.0\t0.06423034330011074\n",
            "\n",
            "-------------\n",
            "0\t0\t0\t0\t0\t0\t0\t125\t0\t123\t0\t0\t0\t\n",
            "0\t0\t0\t0\t0\t1\t2\t0\t1\t0\t3\t0\t0\t\n",
            "0\t0\t0\t0\t0\t2\t0\t0\t0\t0\t24\t0\t0\t\n",
            "0\t0\t0\t0\t0\t0\t8\t0\t0\t0\t1\t0\t0\t\n",
            "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t504\t\n",
            "0\t0\t0\t3\t0\t0\t7\t0\t0\t0\t2\t1\t0\t\n",
            "0\t0\t0\t41\t0\t0\t0\t0\t0\t0\t1\t0\t0\t\n",
            "194\t0\t0\t0\t0\t0\t0\t0\t0\t102\t0\t0\t0\t\n",
            "0\t0\t4\t0\t0\t0\t0\t0\t0\t0\t5\t1\t0\t\n",
            "153\t0\t0\t0\t0\t0\t0\t59\t0\t0\t0\t0\t0\t\n",
            "0\t0\t1\t4\t0\t2\t0\t0\t0\t0\t0\t0\t0\t\n",
            "0\t0\t0\t1\t0\t1\t0\t0\t0\t0\t0\t0\t0\t\n",
            "0\t0\t0\t0\t430\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
            "-------------\n",
            "{'is a triangle present?': 24, 'is there a blue shape?': 5, 'is a circle present?': 33, 'is there not a circle in the image?': 24, 'is there a circle?': 32, 'is no brown shape present?': 9, 'is there a black shape?': 10, 'is there not a black shape?': 6, 'is no black shape present?': 6, 'is there a rectangle in the image?': 31, 'is no rectangle present?': 30, 'does the image not contain a gray shape?': 4, 'is there not a circle?': 28, 'does the image not contain a circle?': 31, 'is there not a triangle in the image?': 30, 'is there not a green shape in the image?': 4, 'is no green shape present?': 3, 'is there not a yellow shape?': 3, 'is there not a rectangle?': 24, 'is there not a rectangle in the image?': 34, 'is no blue shape present?': 3, 'does the image not contain a rectangle?': 34, 'does the image contain a rectangle?': 40, 'is a rectangle present?': 34, 'is there a triangle?': 25, 'is there not a green shape?': 6, 'is a brown shape present?': 11, 'is there not a brown shape in the image?': 7, 'is no circle present?': 26, 'is there a brown shape in the image?': 8, 'is no triangle present?': 22, 'does the image not contain a brown shape?': 6, 'does the image not contain a triangle?': 20, 'is there a red shape in the image?': 11, 'is there a brown shape?': 11, 'is there a blue shape in the image?': 1, 'is there not a triangle?': 25, 'is there a gray shape?': 9, 'is there a rectangle?': 32, 'is there a circle in the image?': 26, 'is there a gray shape in the image?': 11, 'is a gray shape present?': 8, 'does the image contain a triangle?': 18, 'is there a triangle in the image?': 21, 'does the image contain a brown shape?': 10, 'does the image not contain a blue shape?': 1, 'does the image contain a black shape?': 4, 'is a black shape present?': 7, 'does the image contain a red shape?': 5, 'does the image contain a blue shape?': 3, 'is there not a black shape in the image?': 6, 'does the image contain a gray shape?': 4, 'is a teal shape present?': 5, 'is there not a red shape?': 5, 'does the image contain a circle?': 25, 'is no red shape present?': 4, 'does the image not contain a teal shape?': 2, 'is there a teal shape in the image?': 2, 'is there not a teal shape in the image?': 3, 'is there a red shape?': 6, 'is no yellow shape present?': 3, 'is a red shape present?': 3, 'does the image not contain a red shape?': 1, 'is there not a brown shape?': 8, 'is there a green shape in the image?': 2, 'does the image not contain a green shape?': 3, 'is there a black shape in the image?': 7, 'does the image contain a green shape?': 1, 'is there not a gray shape?': 1, 'is a yellow shape present?': 3, 'is no gray shape present?': 2, 'does the image contain a yellow shape?': 1, 'is no teal shape present?': 3, 'is there a yellow shape in the image?': 2, 'does the image not contain a black shape?': 3, 'is a green shape present?': 1, 'is there not a teal shape?': 1, 'does the image contain a teal shape?': 1, 'does the image not contain a yellow shape?': 2, 'is there a green shape?': 1, 'is there a teal shape?': 1, 'is there not a red shape in the image?': 3, 'is a blue shape present?': 2, 'is there not a yellow shape in the image?': 1}\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "train_X_ims, train_X_seqs, train_Y, test_X_ims, test_X_seqs, test_Y, im_shape, vocab_size, num_answers, all_answers, test_qs, test_answer_indices,test_paths,test_qs = setup()\n",
        "\n",
        "print('\\n--- Building model...')\n",
        "model = build_model(im_shape, vocab_size, num_answers,)\n",
        "\n",
        "model.load_weights('model.h5')\n",
        "predictions = model.predict([test_X_ims, test_X_seqs])\n",
        "\n",
        "# Stats for each answer\n",
        "for idx in range(num_answers):\n",
        "\tpred_values = predictions[:, idx]\n",
        "\tanswer = all_answers[idx]\n",
        "\tprint(f'\\nStatistics for answer {idx}, {answer}')\n",
        "\tmin = np.amin(pred_values)\n",
        "\tmax = np.amax(pred_values)\n",
        "\tmean = np.mean(pred_values)\n",
        "\tprint(f'Min: {min}, Max: {max}, Mean: {mean}')\n",
        "\n",
        "shapes = []\n",
        "yesno = []\n",
        "for i in range(num_answers):\n",
        "  if (all_answers[i] == 'rectangle' or all_answers[i] == 'circle' or all_answers[i] == 'triangle'):\n",
        "    shapes.append(i)\n",
        "  elif all_answers[i] == 'yes' or all_answers[i] == 'no':\n",
        "    yesno.append(i)\n",
        "\n",
        "def return_class(answer):\n",
        "  if answer in shapes:\n",
        "    return 0\n",
        "  if answer in yesno:\n",
        "    return 1\n",
        "  return 2\n",
        "error_matrix = [[0 for _ in range(3)] for _ in range(3)]\n",
        "total_errors = 0\n",
        "\n",
        "color_error_matrix = [[0 for _ in range(num_answers)] for _ in range(num_answers)]\n",
        "questions_wrong = {}\n",
        "\n",
        "for idx in range(len(test_answer_indices)):\n",
        "  # answer numbers for triangle, circle, rectangle\n",
        "  answer = test_answer_indices[idx]\n",
        "  pred = np.argmax(predictions[idx])\n",
        "  if not answer == pred:\n",
        "    total_errors += 1\n",
        "    error_matrix[return_class(answer)][return_class(pred)] += 1\n",
        "    color_error_matrix[answer][pred] += 1\n",
        "    if (return_class(answer) == 1 and return_class(pred) == 1):\n",
        "      if test_qs[idx] in questions_wrong:\n",
        "        questions_wrong[test_qs[idx]] += 1\n",
        "      else:\n",
        "        questions_wrong[test_qs[idx]] = 1\n",
        "\n",
        "print('\\n\\ntotal error: {}'.format(total_errors / len(test_answer_indices)))\n",
        "print('Indexes are, in order, shapes, yes/no, colors')\n",
        "print('Rows are class of answer, columns are class of prediction')\n",
        "for i in range(3):\n",
        "  print('{}\\t{}\\t{}\\n'.format(error_matrix[i][0] / total_errors, error_matrix[i][1] / total_errors, error_matrix[i][2]/ total_errors))\n",
        "print('-------------')\n",
        "for i in range(num_answers):\n",
        "  to_print = ''\n",
        "  for j in range(num_answers):\n",
        "    to_print += str(color_error_matrix[i][j]) + '\\t'\n",
        "  print(to_print)\n",
        "print('-------------')\n",
        "print(questions_wrong)\n",
        "\n",
        "\n",
        "# print('examples')\n",
        "\n",
        "# img = mpimg.imread(test_paths[1])\n",
        "# imgplot = plt.imshow(img)\n",
        "# plt.show()\n",
        "# print('Question Example :',test_qs[2])\n",
        "# print(predictions.shape)\n",
        "# pred = np.argmax(predictions[1,2])\n",
        "# print('predicted answer :',pred)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}